## training

ç¬¬ä¸€æ¬¡åšAIé¢˜ï¼Œæ²¡åšå‡ºæ¥ã€‚

Copyä¸€ä¸‹[N0wayBack](https://mp.weixin.qq.com/s/wdo3HCQh8ShgwHXHo6ZvyQ)çš„WPï¼Œå­¦ä¹ ä¸‹tensorflowï¼Œå­¦ä¹ ä¸‹æ€è·¯ã€‚

æ¨¡å‹æ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åæ„å»ºäº†æ–°çš„å¯†é›†å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ï¼Œè®­ç»ƒåªæ›´æ–°æ–°çš„å¯†é›†å±‚å’Œè¾“å‡ºå±‚ã€‚

[Keraså­¦ä¹ ç¬”è®°(ä¸€)ï¼š Application å„modelå‚æ•°åŠåº”ç”¨](https://blog.csdn.net/XM_no_homework/article/details/89813367)

æ¨¡å‹æƒé‡ ğŸ‘‰ [Release Updates new weights Â· JonathanCMitchell/mobilenet_v2_keras (github.com)](https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/tag/v1.1)

ä¸‹è½½çš„æ¨¡å‹æƒé‡éœ€è¦ä¸å®šä¹‰çš„`MobileNetV2`é€‚åº”(`input_shape=(224, 224, 3), include_top=False`)

```Python
# Import Data Science Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from PIL import Image

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers,models
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import Model
from tensorflow.keras.layers.experimental import preprocessing

# System libraries
from pathlib import Path
import os.path

# Metrics
from sklearn.metrics import classification_report, confusion_matrix
import itertools
#!ls /
#!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
#!cp /kaggle/input/help-dataset/helper_functions.py ./helper_functions.py 
# Import series of helper functions for our notebook
from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot
BATCH_SIZE = 32
IMAGE_SIZE = (224, 224)
# Walk through each directory
dataset = "../input/train-data/"
walk_through_dir(dataset)
image_dir = Path(dataset)

# Get filepaths and labels
filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

# Concatenate filepaths and labels
image_df = pd.concat([filepaths, labels], axis=1)
import matplotlib.image as mpimg
# Display 16 picture of the dataset with their labels
random_index = np.random.randint(0, len(image_df), 16)
fig, axes = plt.subplots(
    nrows=4, ncols=4, figsize=(10, 10), 
    subplot_kw={'xticks': [], 'yticks': []}
)

for i, ax in enumerate(axes.flat):
    image = Image.open(image_df.Filepath[random_index[i]])
    ax.imshow(image)
    ax.set_title(image_df.Label[random_index[i]])
plt.tight_layout()
plt.show()
# Separate in train and test data
train_df, test_df = train_test_split(image_df, test_size=1e-7, shuffle=True, random_state=42)
train_generator = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,
    validation_split=1e-7
)

test_generator = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input
)

# Split the data into three categories.
train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)
# Load the pretained model
pretrained_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights=None,
    pooling='avg'
)
pretrained_model.load_weights('/kaggle/input/mobilenet-v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')

pretrained_model.trainable = False

# Create checkpoint callback
checkpoint_path = "fires_classification_model_checkpoint"
checkpoint_callback = ModelCheckpoint(checkpoint_path,
                                      save_weights_only=True,
                                      monitor="val_accuracy",
                                      save_best_only=True)
# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs
early_stopping = EarlyStopping(monitor = "val_loss", # watch the val loss metric
                               patience = 5,
                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training
inputs = pretrained_model.input

x = Dense(256, activation='relu')(pretrained_model.output)
x = Dropout(0.2)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.2)(x)


outputs = Dense(2, activation='softmax')(x)

model = Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer=Adam(0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    steps_per_epoch=len(train_images),
    validation_data=val_images,
    validation_steps=len(val_images),
    epochs=15
)

model.save('model_new.h5')
```

